{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a48688-3200-4c33-8ee9-cec76bf87099",
   "metadata": {},
   "source": [
    "# Waste_Image_Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6631f13-cdd8-4917-a5a6-4ff2c191a78f",
   "metadata": {},
   "source": [
    "Objective : The objective of this project is to develop a deep learning model, specifically a Convolutional Neural Network (CNN), to classify waste images into different categories of materials, using accuracy as the evaluation metric. This aims to assist in automating waste sorting processes, enhancing recycling efficiency, and promoting environmental sustainability. Manual waste sorting is inefficient, leading to low recycling rates and increased environmental harm. Our goal is to develop a deep learning-based waste classification system using a Convolutional Neural Network (CNN) that can accurately classify at least 70% (accuracy) of waste images across 9 material categories within a 12-week timeframe. The project aims to improve waste management efficiency and environmental sustainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6346bfc0-c390-48af-bee7-ff3d633661e8",
   "metadata": {},
   "source": [
    "## Problem Identification\n",
    "In this project, we will define the problem statement and its goals using the SMART framework, then we will analyze it further by breaking down the problem into questions.\n",
    "\n",
    "Topic : Real Waste Classification\n",
    "\n",
    "### Background\n",
    "In modern society, waste management is a significant environmental and operational challenge. Proper waste classification can improve recycling rates and reduce environmental impact, but manual sorting is time-consuming and prone to errors. Leveraging deep learning models to classify waste materials can greatly assist in automating this process, reducing both costs and the need for human labor while improving the accuracy of waste sorting.\n",
    "\n",
    "### Problem statement\n",
    "\"Manual waste sorting is inefficient, leading to low recycling rates and increased environmental harm. Our goal is to develop a deep learning-based waste classification system using a Convolutional Neural Network (CNN) that can accurately classify at least 70% of waste images across 9 material categories within a 12-week timeframe. The project aims to improve waste management efficiency and environmental sustainability.\"\n",
    "\n",
    "### Breaking Down The Problem\n",
    "Main problem: Developing a CNN-based deep learning model capable of accurately classifying waste images into distinct material types (e.g., plastic, metal, glass, etc.).\n",
    "\n",
    "How can the dataset be pre-processed to ensure high model accuracy?\n",
    "What is the most effective CNN architecture/model for this classification task?\n",
    "How can the model be evaluated and optimized for real-world applications in waste management?\n",
    "Dataset Description\n",
    "The dataset used in this analysis is the RealWaste dataset, obtained from the UC Irvine Machine Learning Repository. This dataset contains an image classification dataset of waste items across 9 major material types, collected within an authentic (real data) landfill environment. RealWaste was created as apart of an honors thesis researching how convolution neural networks could perform on authentic waste material when trained on objects in pure and unadulterated forms, when compared to training via real waste items. Color images of waste items captured at the point of reception in a landfill environment. Images are released in 524x524 resolution in line with accompanying research paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b2cf2-55e1-4344-b741-c109f8cbca44",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1dedf5-04a9-4977-abf4-7e86fa706248",
   "metadata": {},
   "source": [
    "#### Import libraries for data loading\n",
    "- import os\n",
    "- import random\n",
    "\n",
    "#### Import libraries for data operations\n",
    "- import numpy as np\n",
    "- import pandas as pd\n",
    "- import math\n",
    "\n",
    "#### Import libraries for data visualization\n",
    "- import matplotlib.pyplot as plt\n",
    "- import seaborn as sns\n",
    "- import cv2\n",
    "- from PIL import Image\n",
    "- import textwrap\n",
    "\n",
    "\n",
    "#### Import libraries for feature engineering\n",
    "- from sklearn.model_selection import train_test_split\n",
    "- import tensorflow as tf\n",
    "- from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "#### Import libraries for model creation\n",
    "- from keras.models import Sequential\n",
    "- from keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "#### Import libraries for model training\n",
    "- from sklearn.utils import class_weight\n",
    "- from tensorflow.keras.optimizers import Adam\n",
    "- from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#### Import libraries for model evaluation\n",
    "- from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#### Import libraries for pre-trained model\n",
    "- from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "#### Import libraries for warnings \n",
    "- import warnings\n",
    "- warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34b53806-656b-4a04-ad71-398aeb5071c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data loading\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147eafde-0af5-49ec-95d1-633fb404dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data operations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "525a6bf6-d242-4ae9-aa38-21f0e1790069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b495d4b-aaf2-4627-80c9-1db137710cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for feature engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b245805-e183-4b77-a953-5d8c1e1efc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for model creation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5311783-3962-4609-bcc2-683cd472f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for model training\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d06877b-c910-4e34-b48d-e61cd59f2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for model evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05a06664-eda7-4f4a-b658-a06af8f0d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for pre-trained model\n",
    "from tensorflow.keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3fce02a-204d-4692-820d-b1dffb7df07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9123d-c9a8-45ae-a26f-d0e13fca7492",
   "metadata": {},
   "source": [
    "To ensure that TensorFlow is properly utilizing the GPU for our deep learning tasks, we will perform some additional steps. These steps include checking if TensorFlow is built with CUDA support, listing available GPUs, configuring TensorFlow to use GPU memory growth, and verifying that TensorFlow is indeed using the GPU. By implementing these checks, we can optimize our model's performance and take full advantage of the GPU's computational power. This will be particularly beneficial for training our complex neural network models, potentially reducing training time and improving overall efficiency. This needs to be done because in this project, we will run it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "364dc383-d177-45ad-bac8-a3d4468a9a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is TensorFlow using GPU: False\n",
      "Available GPUs: []\n"
     ]
    }
   ],
   "source": [
    "# Check if TensorFlow is using GPU\n",
    "print(\"Is TensorFlow using GPU:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "# List available GPUs\n",
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Set TensorFlow to use GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbda08d-de3e-420f-8670-2b9c36140f02",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70604532-70bc-40e8-bb86-c44a3151b443",
   "metadata": {},
   "source": [
    "To begin our analysis, we'll start by loading our dataset and creating a structured dataframe. This approach will facilitate our subsequent analytical processes. Our image data, originally sourced from UCI Machine Learning Repository, has been downloaded and then uploaded to a local directory. As we're running this notebook locally, we'll need to set up the appropriate file paths to access our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cc4fba6-928c-4c3b-bf19-3096ff0b42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset\n",
    "dataset_path = r\"C:\\Users\\LENOVO\\OneDrive\\Desktop\\wet_data\\TrashType_Image_Dataset\"\n",
    "\n",
    "# Define classes\n",
    "classes = [\"Cardboard\", \"Glass\", \"Metal\", \"Paper\", \"Plastic\", \"trash\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61420f89-36d8-442f-a12a-a023f0eeeb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6\n",
      "Class names: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the dataset\n",
    "#dataset_path = r\"C:\\Users\\LENOVO\\OneDrive\\Desktop\\wet_data\\TrashType_Image_Dataset\"\n",
    "\n",
    "# List the subdirectories in the dataset directory\n",
    "classes = os.listdir(dataset_path)\n",
    "\n",
    "# Print the number of classes and their names\n",
    "print(f\"Number of classes: {len(classes)}\")\n",
    "print(\"Class names:\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c13ca4-9674-4cab-81c0-813d339593f7",
   "metadata": {},
   "source": [
    "The next step is to define the paths to each folder and specify the classes for the images. This setup is essential for organizing the data and ensuring efficient access during model training and evaluation. By creating a structured representation of our dataset, we can easily iterate through the images, associate them with their respective classes, and prepare them for input into our machine learning model. This organization will facilitate smooth data loading, preprocessing, and ultimately contribute to the effectiveness of our image classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd240ebd-d0c1-44e1-9eb6-ecad747d2c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths to dataset folder:\n",
      "Dataset Path: C:\\Users\\LENOVO\\OneDrive\\Desktop\\wet_data\\TrashType_Image_Dataset\n",
      "\n",
      "Files in each folder:\n",
      "\n",
      "cardboard:\n",
      "  - cardboard_001.jpg\n",
      "  - cardboard_002.jpg\n",
      "  - cardboard_003.jpg\n",
      "  - cardboard_004.jpg\n",
      "  - cardboard_005.jpg\n",
      "  ... and 398 more files\n",
      "\n",
      "glass:\n",
      "  - glass_001.jpg\n",
      "  - glass_002.jpg\n",
      "  - glass_003.jpg\n",
      "  - glass_004.jpg\n",
      "  - glass_005.jpg\n",
      "  ... and 496 more files\n",
      "\n",
      "metal:\n",
      "  - metal_001.jpg\n",
      "  - metal_002.jpg\n",
      "  - metal_003.jpg\n",
      "  - metal_004.jpg\n",
      "  - metal_005.jpg\n",
      "  ... and 405 more files\n",
      "\n",
      "paper:\n",
      "  - paper_001.jpg\n",
      "  - paper_002.jpg\n",
      "  - paper_003.jpg\n",
      "  - paper_004.jpg\n",
      "  - paper_005.jpg\n",
      "  ... and 589 more files\n",
      "\n",
      "plastic:\n",
      "  - plastic_001.jpg\n",
      "  - plastic_002.jpg\n",
      "  - plastic_003.jpg\n",
      "  - plastic_004.jpg\n",
      "  - plastic_005.jpg\n",
      "  ... and 477 more files\n",
      "\n",
      "trash:\n",
      "  - trash_001.jpg\n",
      "  - trash_002.jpg\n",
      "  - trash_003.jpg\n",
      "  - trash_004.jpg\n",
      "  - trash_005.jpg\n",
      "  ... and 132 more files\n"
     ]
    }
   ],
   "source": [
    "# Define the paths for each class\n",
    "class_paths = {cls: os.path.join(dataset_path, cls) for cls in classes}\n",
    "\n",
    "# Function to list files in a directory\n",
    "def list_files(directory_path):\n",
    "    return os.listdir(directory_path)\n",
    "\n",
    "# List files in each directory\n",
    "print(\"Paths to dataset folder:\")\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "print(\"\\nFiles in each folder:\")\n",
    "for cls, path in class_paths.items():\n",
    "    files = list_files(path)\n",
    "    print(f\"\\n{cls}:\")\n",
    "    for file in files[:5]:  # Display only the first 5 files\n",
    "        print(f\"  - {file}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"  ... and {len(files) - 5} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ccf1f-1915-4449-823d-14112f0e3a38",
   "metadata": {},
   "source": [
    "The next step is to count the total number of images in each folder to determine their number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c04adc8-22e6-4f50-81df-8fbeb0213f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>paper</th>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glass</th>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plastic</th>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metal</th>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardboard</th>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trash</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Number of Images\n",
       "paper                   594\n",
       "glass                   501\n",
       "plastic                 482\n",
       "metal                   410\n",
       "cardboard               403\n",
       "trash                   137"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to count files in a folder\n",
    "def count_files(folder_path):\n",
    "    file_list = os.listdir(folder_path)\n",
    "    return len(file_list)\n",
    "\n",
    "# Create a dictionary with class names and counts\n",
    "classes_dict = {cls: count_files(class_paths[cls]) for cls in classes}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "classes_df = pd.DataFrame.from_dict(classes_dict, orient='index', columns=['Number of Images'])\n",
    "\n",
    "# Sort the DataFrame by 'Number of Images' in descending order\n",
    "classes_df_sorted = classes_df.sort_values('Number of Images', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "classes_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05568134-9835-4dae-bf0b-852681aa844e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
